{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NDzS-vGbJAgA",
        "TCPjizpwjolY",
        "iQfeQTJIwdoX",
        "Id-OKdU7fxaC",
        "CxPK8JlAiF0v",
        "1aGxWBNaRfOL",
        "TzwW95XTplQd"
      ],
      "authorship_tag": "ABX9TyPv3x35aiaM7JI0Q4rGEHSU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ken-huea/Language-processing/blob/main/%E2%91%A0%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E5%9F%BA%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自然言語処理 とは"
      ],
      "metadata": {
        "id": "NDzS-vGbJAgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "自然言語：自然発生的に生まれた言語 のこと。例：英語や日本語。\n",
        "\n",
        "人工言語：プログラミング言語、エスペラント⇒エスペラントは面白いからググってみて。\n",
        "\n",
        "<font color=\"red\">自然言語処理</font>：自然言語(英語日本語)をコンピュータに処理させる技術。\n",
        "日本語をそのままPCは理解できないわけですよ。PCに理解させるために翻訳してあげる事。\n",
        "\n",
        "身近では、`文書分類・機械翻訳・文書要約・検索エンジンやsiri・チャットボット`等の技術が用いられている。"
      ],
      "metadata": {
        "id": "UL6SjwJKJ8IQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学ぶ上での簡単な<font color=\"red\">ボキャブラリ</font>.サラッと確認する程度でも。\n",
        "\n",
        "・**トークン**：自然言語を解析する際、文章の最小単位として扱われる文字や文字列のこと。\n",
        "\n",
        "・**タイプ**：単語の種類を表す用語。\n",
        "\n",
        "・**文章**：まとまった内容を表す文のこと。自然言語処理では一文を指すことが多い。\n",
        "\n",
        "・**文書**：複数の文章から成るデータ一件分を指すことが多い。\n",
        "\n",
        "・**コーパス**：文書または音声データにある種の情報を与えたデータ。\n",
        "\n",
        "・**シソーラス**：単語の上位/下位関係、部分/全体関係、同義関係、類義関係などによって単語を分類し、体系づけた類語辞典・辞書。"
      ],
      "metadata": {
        "id": "EpCG9-WDK_6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**単語分割**：文章を単語に分割すること\n",
        "\n",
        "**品詞タグ付け**：単語を品詞に分類して、タグ付けをする処理のこと\n",
        "\n",
        "**単語**：単一または複数の形態素から構成される小さな単位。\n",
        "\n",
        "**表層**<font color=\"red\">surface</font>：原文の記述のこと。\n",
        "\n",
        "**原形**：活用する前の記述のこと。\n",
        "\n",
        "**特徴**<font color=\"red\">feature</font>：文章や文書から抽出された情報のこと。\n",
        "\n",
        "**辞書**：自然言語処理では、単語のリストを指す。\n"
      ],
      "metadata": {
        "id": "fJXH3qj_LPui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自然言語処理基本的動作の実装\n",
        "形態素解析とNgram"
      ],
      "metadata": {
        "id": "Vd8H5vElv-ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 形態素解析と分かち書き。\n",
        "形態素解析の中に分かち書きが含まれています。そして今回使用するのは<font color=\"red\">Janome</font>"
      ],
      "metadata": {
        "id": "NgoztLy8t9Hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**形態素**：意味を持つ最小の単位。「食べた」という単語は、2つの形態素「食べ」と「た」に分解できる。\n",
        "\n",
        "**形態素解析**：形態素への分割と品詞タグ付けの作業をまとめたもの ⇒<font color=\"red\">後述</font>"
      ],
      "metadata": {
        "id": "ltB-HrtWlTuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# moduleのインポート\n",
        "!pip install janome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uccR1nojuUGq",
        "outputId": "98dcc5aa-a598-462c-f45e-577d41829359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分かち書き"
      ],
      "metadata": {
        "id": "DaYlPXAGuGeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 単純に文章を単語ごとにぶった切る。\n",
        "\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "# インスタンスの作成\n",
        "t = Tokenizer()\n",
        "\n",
        "# 分かち書きの実施 ⇒ wakati=True という事です。\n",
        "tokens = t.tokenize(\"pythonの本を読んだ\", wakati=True)\n",
        "\n",
        "# print(tokens) # 下記のコードなら動くけど…。\n",
        "\n",
        "# 表層系：つまり実際にビジュアルとして確認するにはこう。\n",
        "print(type(tokens))\n",
        "for token in tokens:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347ff3da-f801-4b02-b853-7c8da763ed87",
        "id": "PS94WS8TuDLE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'generator'>\n",
            "python\n",
            "の\n",
            "本\n",
            "を\n",
            "読ん\n",
            "だ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "形態素解析　そして文章は変数に入れておくと後々便利。"
      ],
      "metadata": {
        "id": "VG2xMGnhuJGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 単語ごとにぶった切る。(分かち書き)＋ 単語の詳細な情報も表示させる\n",
        "\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "text = \"pythonの本を読んだ。その上だ食べたい\"\n",
        "\n",
        "tokenizer = Tokenizer()  # インスタンスの作成\n",
        "\n",
        "# インスタンスの作成\n",
        "tokens = tokenizer.tokenize(text)\n",
        "for token in tokens:\n",
        "    print(token)\n",
        "    print(\"------------------------------------\")    # 分かりやすく区切り棒を入れてみました。"
      ],
      "metadata": {
        "id": "IoWI9rSHtv_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aab259d-30d0-439e-92f3-26499929a897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python\t名詞,固有名詞,組織,*,*,*,python,*,*\n",
            "------------------------------------\n",
            "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
            "------------------------------------\n",
            "本\t名詞,一般,*,*,*,*,本,ホン,ホン\n",
            "------------------------------------\n",
            "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
            "------------------------------------\n",
            "読ん\t動詞,自立,*,*,五段・マ行,連用タ接続,読む,ヨン,ヨン\n",
            "------------------------------------\n",
            "だ\t助動詞,*,*,*,特殊・タ,基本形,だ,ダ,ダ\n",
            "------------------------------------\n",
            "。\t記号,句点,*,*,*,*,。,。,。\n",
            "------------------------------------\n",
            "その\t連体詞,*,*,*,*,*,その,ソノ,ソノ\n",
            "------------------------------------\n",
            "上\t名詞,非自立,副詞可能,*,*,*,上,ウエ,ウエ\n",
            "------------------------------------\n",
            "だ\t助動詞,*,*,*,特殊・ダ,基本形,だ,ダ,ダ\n",
            "------------------------------------\n",
            "食べ\t動詞,自立,*,*,一段,連用形,食べる,タベ,タベ\n",
            "------------------------------------\n",
            "たい\t助動詞,*,*,*,特殊・タイ,基本形,たい,タイ,タイ\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "因みに日本語は言語学上、<font color=\"red\">形態素解析が難しい言語</font>らしいから頑張ろう。"
      ],
      "metadata": {
        "id": "9-pdJlKqx-Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">応用問題</font>\n",
        "\n",
        "文から名詞と動詞を抽出し、各リストに格納せよ。\n"
      ],
      "metadata": {
        "id": "OqPlD0qi4kuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "t = Tokenizer()\n",
        "\n",
        "tex = \"豚の肉を食べた\"\n",
        "tokens = t.tokenize(tex)\n",
        "\n",
        "# 以下のリストに答えを代入してください\n",
        "noun = []\n",
        "verb = []\n",
        "\n",
        "# 以下に回答を作成してください \n",
        "for token in tokens:\n",
        "  part_of_speech = token.part_of_speech.split(\",\")[0]\n",
        "  if part_of_speech == \"名詞\":\n",
        "    noun.append(token.surface)\n",
        "    # noun.append(token.feature)\n",
        "  elif part_of_speech == \"動詞\":\n",
        "    verb.append(token.surface)\n",
        "    # noun.append(token.feature)"
      ],
      "metadata": {
        "id": "JA-Fmwue6gHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(noun)\n",
        "print(verb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Nai3Ef61y2",
        "outputId": "5e8367b2-63d3-4201-c19a-30a4883cf7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['豚', '肉']\n",
            "['食べ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 形態素解析を含めたもの。\n",
        "\n",
        "tex = \"豚の肉を食べた\"\n",
        "nodes = t.tokenize(tex)\n",
        "\n",
        "noun = []\n",
        "verb = []\n",
        "\n",
        "for node in nodes:\n",
        "  print(\"This is node.surface:\",node.surface) #追加 文章から形態素解析後の単語を抽出 単語に関する。\n",
        "  print(\"This is node.feature:\",node.part_of_speech) #追加 品詞などの詳細が取得 品詞全般に関する。 feature ⇒ part_of_speech\n",
        "  print(\"---------------------------------------------------------------\")\n",
        "  if node.part_of_speech.split(\",\")[0] == \"名詞\":\n",
        "    noun.append(node.surface)\n",
        "  elif node.part_of_speech.split(\",\")[0] == \"動詞\":\n",
        "    verb.append(node.surface)\n",
        "    # verb.append(node.part_of_speech)  #原型を取ってこれるはず。"
      ],
      "metadata": {
        "id": "Y_sRi8Ru60s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a777c0-d4ba-41b7-b7ea-1554cf36257f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is node.surface: 豚\n",
            "This is node.feature: 名詞,一般,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: の\n",
            "This is node.feature: 助詞,連体化,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: 肉\n",
            "This is node.feature: 名詞,一般,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: を\n",
            "This is node.feature: 助詞,格助詞,一般,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: 食べ\n",
            "This is node.feature: 動詞,自立,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: た\n",
            "This is node.feature: 助動詞,*,*,*\n",
            "---------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(noun)\n",
        "print(verb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoXAy4MuobIR",
        "outputId": "47c9d381-45b2-43ea-8915-da9735c9f878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['豚', '肉']\n",
            "['食べ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "import re #追加\n",
        "\n",
        "tex = \"豚の肉を食べた\"\n",
        "nodes = t.tokenize(tex)\n",
        "noun = []\n",
        "verb = []\n",
        "for node in nodes:\n",
        "  print(\"This is node.surface:\",node.surface) #追加 文章から形態素解析後の単語を抽出 単語に関する。\n",
        "  print(\"This is node.feature:\",node.part_of_speech) #追加 品詞などの詳細が取得 品詞全般に関する。 feature ⇒ part_of_speech\n",
        "  print(\"---------------------------------------------------------------\")\n",
        "  if node.part_of_speech.split(\",\")[0] == \"名詞\":\n",
        "    noun.append(node.surface)\n",
        "  elif node.part_of_speech.split(\",\")[0] == \"動詞\":\n",
        "    base_form = re.split('\\t|,', str(node))[7]      #追加\n",
        "    verb.append(base_form)                          #追加\n",
        "print(noun)\n",
        "print(verb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5oxL5-c9_7R",
        "outputId": "d57c9083-fce0-4f5e-eaae-69f40ab76326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is node.surface: 豚\n",
            "This is node.feature: 名詞,一般,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: の\n",
            "This is node.feature: 助詞,連体化,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: 肉\n",
            "This is node.feature: 名詞,一般,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: を\n",
            "This is node.feature: 助詞,格助詞,一般,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: 食べ\n",
            "This is node.feature: 動詞,自立,*,*\n",
            "---------------------------------------------------------------\n",
            "This is node.surface: た\n",
            "This is node.feature: 助動詞,*,*,*\n",
            "---------------------------------------------------------------\n",
            "['豚', '肉']\n",
            "['食べる']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ngram\n",
        "N文字ごとに単語を切り分ける。N単語ごとに文章を切り分ける。 検索インデックス作成などに用いられる"
      ],
      "metadata": {
        "id": "TCPjizpwjolY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "例：\n",
        "\n",
        "①**モノグラム**：1文字、あるいは1単語ごとに　　　　：{あ, い, う, え, お}\n",
        "\n",
        "②**バイグラム**：2文字（単語）ごとに切り出したもの　：{あい, いう, うえ, えお}\n",
        "\n",
        "③**トリグラム**：3文字（単語）ごとに切り出したもの　：{あいう, いうえ, うえお}"
      ],
      "metadata": {
        "id": "1aBW7obYj4oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ngram は**文法的な解釈が不要**⇒ 言語に関係なく利用可能。 \n",
        "\n",
        "メリット：特徴抽出の漏れが発生しにくい。\n",
        "\n",
        "デメリッド：ノイズが大きくなる"
      ],
      "metadata": {
        "id": "b0nWPk6Xkc3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='私は、先週の日曜日に、東京へ観光へ行きました。'\n",
        "len(text)"
      ],
      "metadata": {
        "id": "CTDAnMYs0PjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngram=[] # 用を格納するリストの作成\n",
        "\n",
        "# 第一引数：文章を格納した変数　第二引数：分割する数字\n",
        "def get_ngram(text,n):\n",
        "    sub_text=''\n",
        "    for i in range(len(text)-n):\n",
        "        ngram.append(text[i:i+n])\n",
        "    \n",
        "    return ngram\n",
        "\n",
        "# (テキストの文字数-n)回forを回している。\n",
        "# 追加する列、1:4,2:5 とどんどん更新されていく。"
      ],
      "metadata": {
        "id": "q93G6PB90sf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3文字ごとに抽出されておりますね。\n",
        "ngram = get_ngram(text,3)\n",
        "print(ngram)"
      ],
      "metadata": {
        "id": "QC3W8wul0vH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### splitメソッド。\n",
        "\n"
      ],
      "metadata": {
        "id": "iQfeQTJIwdoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**数字・アルファベット・記号などが入り混じった文字列**を、ある規則に従って切り分けてリスト化する関数"
      ],
      "metadata": {
        "id": "JDJWS3asw4gB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "文字列がスペース等(「,」, 「.」, 「_」など)によって区切られている。\n",
        "\n",
        "**文字列.split(\"区切り文字\")** ⇒区切られたリストを得る"
      ],
      "metadata": {
        "id": "jAvn72Jww7hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割。　分割に使用した材料は消えてしまいますね。\n",
        "a = \"こんにちは。こんばんは。ありがとうございます。\"\n",
        "print(a)\n",
        "a.split(\"。\") # (\",\") 「.split()」こうすれば空欄区切りも可能。\n",
        "\n",
        "# こんにちは。こんばんは。ありがとうございます。⇒このように「。」という文字で区切っている。\n",
        "# ['こんにちは', 'こんばんは', 'ありがとうございます', '']"
      ],
      "metadata": {
        "id": "koas6raG-8vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 正規化\n",
        "入力された無秩序な言葉の羅列をある程度統一させる事"
      ],
      "metadata": {
        "id": "Id-OKdU7fxaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "入力ルールが統一されていないと、表記ゆれが発生してしまう。\n",
        "\n",
        "**表記揺れ**：同じ文書の中で、同音・同義で使われるべき語句が異なって表記されていること　\n",
        "例 ：　<font color=\"red\">iPhoneとiphone\n",
        "</font>\n",
        "\n",
        "同じはずの単語を別のものとして解析してしまうと\n",
        "⇒<font color=\"red\">意図しない解析結果</font>になってしまう。\n",
        "\n",
        "それを防ぐための<font color=\"blue\">正規化</font>"
      ],
      "metadata": {
        "id": "wZzIg-JZf1cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  実装"
      ],
      "metadata": {
        "id": "CxPK8JlAiF0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NEologd\n",
        "正規化の自動ツール。"
      ],
      "metadata": {
        "id": "1aGxWBNaRfOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "・全角英数字を半角に統一　　　：ａｉ -> ai\n",
        "\n",
        "・半角カタカナを全角に統一 　 ：ｶﾀｶﾅ -> カタカナ\n",
        "\n",
        "・長音短縮 　　　　　　　　　  :ワーーーーーーーーイ -> ワーイ\n",
        "\n",
        "・似た文字種の統一 　　　　　　：\"− ー - \"-> \"-\"\n",
        "\n",
        "・不必要なスペースの削除 　　　：\"ス ペ ース \"-> \"スペース\"　\n",
        "繰り返しの制限 （問題で確認）"
      ],
      "metadata": {
        "id": "uvMQ2huPhqFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install neologdn"
      ],
      "metadata": {
        "id": "Ge_Pm2G-Poff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neologdnをインポートしてください\n",
        "import neologdn"
      ],
      "metadata": {
        "id": "94rDfjkijG83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 半角カタカナを全角に統一\n",
        "a = neologdn.normalize(\"ｶﾀｶﾅ\")\n",
        "print(a)\n",
        "\n",
        "# 長音短縮\n",
        "b = neologdn.normalize(\"アイデミーーーーーーーー\")\n",
        "print(b)\n",
        "\n",
        "# 似た文字の統一\n",
        "c = neologdn.normalize(\"いろんなハイフン˗֊‐‑‒–⁃⁻₋−\")\n",
        "print(c)\n",
        "\n",
        "# 全角英数字を半角に統一 + 不要なスペースの削除\n",
        "d = neologdn.normalize(\"　　　ＤＬ　　デ ィ ープ ラ ーニング　　　　　\")\n",
        "print(d)\n",
        "\n",
        "# 繰り返しの制限 [い]の数が20こあるんです。しかし repeat=3 にした事で３つしか表示されておりません。\n",
        "e = neologdn.normalize(\"あいでみいいいいいいいいいいいいいいいいいいいいい\", repeat=3)\n",
        "print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zo4Kehji9Fj",
        "outputId": "fb09cbb4-01b7-498e-f544-b67c981d6797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "カタカナ\n",
            "アイデミー\n",
            "いろんなハイフン-\n",
            "DLディープラーニング\n",
            "あいでみいいい\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数値の正規化\n",
        "数字表現を潰す処理。"
      ],
      "metadata": {
        "id": "TzwW95XTplQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "自然言語処理を行う際に<font color=\"red\">数字の情報が役に立たない</font>事は多々あるそうです。　もはや**ノイズ**って位に。\n",
        "\n",
        "その時は、数字を別の記号に置き換えて語彙数を減らしてしまおう。という事。"
      ],
      "metadata": {
        "id": "T6exHR21SoEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        " re.sub(\"\\d\", \"<NUM>\", text)\n",
        "```\n",
        "第一引数：置き換えたいもの(今回は数字)　第二引数：何で置き換えるのか(今回はNUM)　第三引数：文章 ```\"\\d\"は数字の事です。```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lt_Ii2eGTUnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モジュールのインポート\n",
        "import re\n",
        "\n",
        "tes2 = \"昨日は6時に起きて11時に寝た。\"\n",
        "\n",
        "a = re.sub(\"\\d\", \"<NUM>\", tes2)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aWZIJnu-Tm4f",
        "outputId": "7a629dcc-9804-43f0-92d0-ea67f44d102c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'昨日は<NUM>時に起きて<NUM><NUM>時に寝た。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 独自関数だとこんな感じ。\n",
        "\n",
        "tes3 = \"終日は前日よりも39.03ドル(0.19%)高い。\"\n",
        "def normalize_number(text):\n",
        "    replaced_text = re.sub(\"\\d\", \"!\", text)\n",
        "    return replaced_text\n",
        "\n",
        "print(normalize_number(tes3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVN02bvcUs0D",
        "outputId": "c3ff7481-5a5d-43a2-a4ff-9892105aa098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "終日は前日よりも!!.!!ドル(!.!!%)高い。\n"
          ]
        }
      ]
    }
  ]
}